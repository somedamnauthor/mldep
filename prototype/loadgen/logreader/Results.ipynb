{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9615f9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logfile = 'log_bert.csv'\n",
    "# logfile = 'logs_resnet50.csv'\n",
    "# # logfile = '../alexnet_log.csv'\n",
    "# # logfile = 'logs_gpt2.csv'\n",
    "# logfile = 'resnet_log.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70141f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf952729",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(logfile):    \n",
    "    \n",
    "    # Read the file line by line and convert each line to a list using ast.literal_eval\n",
    "    data = []\n",
    "    with open(logfile, 'r') as file:\n",
    "        for line in file:\n",
    "            data.append(ast.literal_eval(line))\n",
    "\n",
    "    # Create a DataFrame from the list of lists with custom column names\n",
    "    df = pd.DataFrame(data, columns=['prediction', 'timestamp', 'prepro_time', 'predict_time', 'total_time'])\n",
    "\n",
    "    # Drop the 'prediction' column\n",
    "#     df.drop('prediction', axis=1, inplace=True)\n",
    "\n",
    "    # Convert 'timestamp' column to datetime and extract the minute value\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    df['minute'] = df['timestamp'].dt.minute\n",
    "    # Add a new column representing the row numbers\n",
    "    df['Request'] = df.index + 1\n",
    "\n",
    "    # Print the DataFrame\n",
    "    df\n",
    "\n",
    "    percentiles = [0.99, 0.9, 0.5]\n",
    "    response_times = df['total_time'].quantile(percentiles)\n",
    "    response_times\n",
    "\n",
    "    avg_rt = df['total_time'].mean()\n",
    "    avg_rt\n",
    "\n",
    "    return response_times, avg_rt, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a463580c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_func(logfile):\n",
    "\n",
    "    # Read the data from the file\n",
    "    with open(logfile, 'r') as file:\n",
    "        data = file.read()\n",
    "\n",
    "    # Split the data into individual JSON objects\n",
    "    json_objects = data.strip().split('}\\n{')  # Assumes there are no spaces between objects\n",
    "\n",
    "    # Add back missing curly braces to make each item a valid JSON object\n",
    "    json_objects = ['{' + obj + '}' for obj in json_objects]\n",
    "\n",
    "    # Parse each JSON object and store them in a list\n",
    "    parsed_data = []\n",
    "    for obj in json_objects:\n",
    "        try:\n",
    "            parsed_data.append(json.loads(obj))\n",
    "        except json.JSONDecodeError:\n",
    "            pass\n",
    "#             print(f\"Failed to parse JSON: {obj}\")\n",
    "\n",
    "    # Create a DataFrame from the parsed data\n",
    "    df = pd.DataFrame(parsed_data)\n",
    "    \n",
    "    data = df['output'].to_list()\n",
    "    \n",
    "    # Remove 'nan' elements using list comprehension\n",
    "    data = [x for x in data if x is not None and not (isinstance(x, float) and math.isnan(x))]\n",
    "\n",
    "    # Flatten the inner lists\n",
    "    flattened_data = []\n",
    "    for item in data:\n",
    "        row = [item[0]] + item[1]\n",
    "        flattened_data.append(row)\n",
    "\n",
    "    # Convert the flattened data into a DataFrame\n",
    "    df = pd.DataFrame(flattened_data, columns=['prediction', 'timestamp', 'prepro_time', 'predict_time', 'total_time'])\n",
    "\n",
    "    # Drop the 'prediction' column\n",
    "    df.drop('prediction', axis=1, inplace=True)\n",
    "\n",
    "    # Convert 'timestamp' column to datetime and extract the minute value\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    df['minute'] = df['timestamp'].dt.minute\n",
    "    # Add a new column representing the row numbers\n",
    "    df['Request'] = df.index + 1\n",
    "\n",
    "    # Print the DataFrame\n",
    "    df\n",
    "\n",
    "    percentiles = [0.99, 0.9, 0.5]\n",
    "    response_times = df['total_time'].quantile(percentiles)\n",
    "    response_times\n",
    "\n",
    "    avg_rt = df['total_time'].mean()\n",
    "    avg_rt\n",
    "\n",
    "    return response_times, avg_rt, df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8078e52a",
   "metadata": {},
   "source": [
    "# Nature of Deployments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449350a4",
   "metadata": {},
   "source": [
    "## Alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cd55eefe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response Time Percentiles:\n",
      " 0.99    0.031107\n",
      "0.90    0.028936\n",
      "0.50    0.025761\n",
      "Name: total_time, dtype: float64\n",
      "Average RT: 0.02592422779868631\n"
     ]
    }
   ],
   "source": [
    "logfile = '../../experiments/00_container_exps/alexnet_log_1hr_container.csv'\n",
    "\n",
    "response_times, avg_rt, df = get_results(logfile)\n",
    "\n",
    "print(\"Response Time Percentiles:\\n\",response_times)\n",
    "print(\"Average RT:\",avg_rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "78ad6f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response Time Percentiles:\n",
      " 0.99    0.041114\n",
      "0.90    0.037637\n",
      "0.50    0.034439\n",
      "Name: total_time, dtype: float64\n",
      "Average RT: 0.03462948933060648\n"
     ]
    }
   ],
   "source": [
    "logfile = '../../experiments/01_vm_exps/alexnet_log_1hr_vm.csv'\n",
    "\n",
    "response_times, avg_rt, df = get_results(logfile)\n",
    "\n",
    "print(\"Response Time Percentiles:\\n\",response_times)\n",
    "print(\"Average RT:\",avg_rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "74e1d184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response Time Percentiles:\n",
      " 0.99    0.024498\n",
      "0.90    0.023814\n",
      "0.50    0.022099\n",
      "Name: total_time, dtype: float64\n",
      "Average RT: 0.02224441675039438\n"
     ]
    }
   ],
   "source": [
    "logfile = '../../experiments/02_func_exps/responses.txt'\n",
    "\n",
    "response_times, avg_rt, df = get_results_func(logfile)\n",
    "\n",
    "print(\"Response Time Percentiles:\\n\",response_times)\n",
    "print(\"Average RT:\",avg_rt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a13431f",
   "metadata": {},
   "source": [
    "## ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c6c9a20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response Time Percentiles:\n",
      " 0.99    0.118116\n",
      "0.90    0.102984\n",
      "0.50    0.081753\n",
      "Name: total_time, dtype: float64\n",
      "Average RT: 0.08499220186028598\n"
     ]
    }
   ],
   "source": [
    "logfile = '../../experiments/00_container_exps/resnet_log_1hr_container.csv'\n",
    "\n",
    "response_times, avg_rt, df = get_results(logfile)\n",
    "\n",
    "print(\"Response Time Percentiles:\\n\",response_times)\n",
    "print(\"Average RT:\",avg_rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "bab924bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response Time Percentiles:\n",
      " 0.99    0.182101\n",
      "0.90    0.164112\n",
      "0.50    0.148082\n",
      "Name: total_time, dtype: float64\n",
      "Average RT: 0.14991033251624555\n"
     ]
    }
   ],
   "source": [
    "logfile = '../../experiments/01_vm_exps/resnet_log_1hr_vm.csv'\n",
    "\n",
    "response_times, avg_rt, df = get_results(logfile)\n",
    "\n",
    "print(\"Response Time Percentiles:\\n\",response_times)\n",
    "print(\"Average RT:\",avg_rt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52af821",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "aea752f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response Time Percentiles:\n",
      " 0.99    0.094091\n",
      "0.90    0.090199\n",
      "0.50    0.076289\n",
      "Name: total_time, dtype: float64\n",
      "Average RT: 0.07738236080516468\n"
     ]
    }
   ],
   "source": [
    "logfile = '../../experiments/00_container_exps/bert_log_1hr_container.csv'\n",
    "\n",
    "response_times, avg_rt, df = get_results(logfile)\n",
    "\n",
    "print(\"Response Time Percentiles:\\n\",response_times)\n",
    "print(\"Average RT:\",avg_rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "efeaf16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response Time Percentiles:\n",
      " 0.99    0.104564\n",
      "0.90    0.092211\n",
      "0.50    0.081577\n",
      "Name: total_time, dtype: float64\n",
      "Average RT: 0.08228314789858732\n"
     ]
    }
   ],
   "source": [
    "logfile = '../../experiments/01_vm_exps/bert_log_1hr_vm.csv'\n",
    "\n",
    "response_times, avg_rt, df = get_results(logfile)\n",
    "\n",
    "print(\"Response Time Percentiles:\\n\",response_times)\n",
    "print(\"Average RT:\",avg_rt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ab884d",
   "metadata": {},
   "source": [
    "## GPT-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f08feef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response Time Percentiles:\n",
      " 0.99    1.537016\n",
      "0.90    1.474117\n",
      "0.50    1.404700\n",
      "Name: total_time, dtype: float64\n",
      "Average RT: 1.374212430823933\n"
     ]
    }
   ],
   "source": [
    "logfile = '../../experiments/00_container_exps/gpt2_log_2.csv'\n",
    "\n",
    "response_times, avg_rt, df = get_results(logfile)\n",
    "\n",
    "print(\"Response Time Percentiles:\\n\",response_times)\n",
    "print(\"Average RT:\",avg_rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4e82e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response Time Percentiles:\n",
      " 0.99    1.544103\n",
      "0.90    1.459034\n",
      "0.50    1.361770\n",
      "Name: total_time, dtype: float64\n",
      "Average RT: 1.3495006209070033\n"
     ]
    }
   ],
   "source": [
    "logfile = '../../experiments/01_vm_exps/gpt2_log_vm_1hr_2.csv'\n",
    "\n",
    "response_times, avg_rt, df = get_results(logfile)\n",
    "\n",
    "print(\"Response Time Percentiles:\\n\",response_times)\n",
    "print(\"Average RT:\",avg_rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1c289218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print([x for x in df['total_time'].to_list() if x > 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ebd0a6",
   "metadata": {},
   "source": [
    "# Containers vs Functions in Conjunction with VMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e0ab1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3810jvsc74a57bd0916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
